# XPath

- 一种再XML文档中查找信息的语言
- 可用于再XML文档中对元素和属性进行遍历
- python使用：
  - 安装lxml库
  - from lxml import etree
  - Selector = etree.HTML(网页源代码)
  - Selector.xpath(一段神奇的符号)

官方文档：http://lxml.de/api/index.html  官网：http://lxml.de



语法

| 表达式   | 描述                                                       |
| :------- | :--------------------------------------------------------- |
| nodename | 选取此节点的所有子节点。                                   |
| /        | 从根节点选取。                                             |
| //       | 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。 |
| .        | 选取当前节点。                                             |
| ..       | 选取当前节点的父节点。                                     |
| @        | 选取属性。                                                 |

参考：https://www.w3school.com.cn/xpath/xpath_syntax.asp





```python
# 使用XPath解析HTML网页内容

# 准备html文件信息
import requests
from lxml import etree

url = "http://www.baidu.com"

res = requests.get(url)

content = res.content.decode("utf-8")

# 使用lxml创建节点对象
html = etree.HTML(content)

# 使用xpath解析网页中的元素节点（标签）
# result = html.xpath("/*") # 获取所有直接子节点 == html
# result = html.xpath("//*") # 获取所有子节点
result = html.xpath("/html/body/div/div/div/div[2]/a[@class='mnav']") # 获取所有div节点
for res in result:
    print(res.tag, end=" ")
print()

# 解析所有的mnav信息
for res in result:
    if res.tag == 'a':
        print(res.get("class"), res.text)
        
#out:
a a a a a 
mnav 新闻
mnav hao123
mnav 地图
mnav 视频
mnav 贴吧
```



# Beatiful Soup

- 一个HTML或XML解析库，最主要的功能是从网页爬取需要的信息
- 将html解析为对象进行处理，全部页面转变为字典或数组，相对于正则表达式，可以大大简化处理过程
- Beatiful  Soup3已停止开发，推荐使用Beatiful  Soup4



### 1. 安装与使用

- 依赖lxml解析库，需要先pip install lxml
- pip install beatifulsoup4
- 官方文档：https://www.crummy.com/software/BeautifulSoup/
- 中文文档：https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/



```python
from bs4 import BeautifulSoup

# 读取html文件信息
f = open("./tmp.html", 'r', encoding='utf-8')
content = f.read()
f.close()

# 创建解析对象
soup = BeautifulSoup(content, "lxml")

# 第一种：节点选择器解析
'''
ddlist = soup.dl.children
for dd in ddlist:
    i = dd
    print(i)
'''

# 第二种： 方法选择器
'''
ddlist = soup.find_all("dd")
for dd in ddlist:
    i = dd.find("i")
    print(i.get_text(),":",i.attrs['class'])
'''

# 第三种：CSS选择器
# print(soup.select("dd i.board-index"))
ddlist = soup.select("dl dd")# 获取url中的所有dd节点
# 遍历
for dd in ddlist:
    i = dd.select("i")[0]
    print(i)
```





# PyQuery

- 一个非常强大又灵活的网页解析库
- 语法与jQuery几乎相同
- 官方网址：http://pyquery.readthedocs.io/en/latest

- pip install pyquery